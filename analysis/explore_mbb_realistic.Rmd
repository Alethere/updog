---
title: "Explore New Distribution"
author: "David Gerard"
date: "November 30, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Abstract

I [previously](https://dcgerard.github.io/mupdog/explore_mbb.html) looked at the new multivariate beta binomial model I created. However, I think the "OD matrix" is unrealistic (marginal values of 0.52 make little sense). Here, I try out a more realistic R. Otherwise, the code is the same.

# Set up OD Matrix and conditional means and conditional od parameters

Choose a correlation matrix based on AR-1(0.9) covariance matrix

```{r}
mu <- 0.3
K <- 6 ## Ploidy of species, or number of samples
rho <- 0.9
n <- 11
R <- rho ^ abs(outer(1:n, 1:n, "-")) * 0.01 ## try decreasing it a little
Sigma <- diag(n) + (K - 1) * R
```

Functions for conditional mean and conditional OD parameter

```{r}
#' @param x A vector of size n. The observed values.
#' @param mu A scalar. The allele frequency.
#' @param Sigma A matrix. The covariance matrix
#' @param i Which individual to calculate the conditional distribution.
#' @param K The ploidy
cond_mean <- function(x, mu, Sigma, i, K) {
  n <- nrow(Sigma)
  assertthat::are_equal(ncol(Sigma), n)
  assertthat::are_equal(length(x), n)
  assertthat::are_equal(length(i), 1)
  assertthat::are_equal(length(mu), 1)
  assertthat::assert_that(K > 1)
  
  Sigma12 <- Sigma[i, (1:n)[-i], drop = FALSE]
  Sigma22 <- Sigma[(1:n)[-i], (1:n)[-i], drop = FALSE]
  mu + Sigma12 %*% solve(Sigma22) %*% (x[-i] / K - rep(mu, n - 1))
}

#' @param R The od param matrix
#' @param K The ploidy.
#' @param i Which individual to look at
cond_od_param <- function(R, K, i) {
  n <- nrow(R)
  assertthat::are_equal(ncol(R), n)
  R11 <- R[i, i, drop = FALSE]
  R12 <- R[i, (1:n)[-i], drop = FALSE]
  R22 <- R[(1:n)[-i], (1:n)[-i], drop = FALSE]
  R11 - R12 %*% solve(diag(x = 1 / (K - 1), nrow = n - 1, ncol = n - 1) + R22) %*% t(R12)
}
```

# MCMC to sample from this distribution

```{r, cache=TRUE}
library(updog) ## for rbetabinom_mu_rho()
max_iter <- 100000
thin <- 100

x <- rbinom(n = n, size = K, prob = mu)
samp_mat <- NULL
for (iter_index in 1:max_iter) {
  for (i in 1:n) {
    mu_cond <- cond_mean(x = x, mu = mu, Sigma = Sigma, i = i, K = K)
    rho_cond <- cond_od_param(R = R, K = K, i = i)
    x[i] <- rbetabinom_mu_rho(mu = mu_cond, rho = rho_cond, size = K)
  }
  if (iter_index %% thin == 0) {
    samp_mat <- rbind(samp_mat, x)
  }
}
```

They all have approximately the correct mean:
```{r}
colMeans(samp_mat) / K
```

```{r}
prop.table(table(samp_mat[, 1]))
```

Compare to beta binomial dist at MLE estimates

```{r}
negative_ll <- function(mu, rho, xtab, size) {
  ll <- 0
  for (index in 0:size) {
    ll <- ll + xtab[index + 1] * updog:::dbetabinom_mu_rho(x = index, size = size, mu = mu, rho = rho, log = TRUE)
  }
  return(-1 * ll)
}
```

The first one
```{r}
xtab <- table(c(samp_mat[, 2], 0:K)) - 1
mlout <- stats4::mle(negative_ll, start = list(mu = 0.3, rho = 0.3), fixed = list(xtab = xtab, size = K), method = "L-BFGS-B", lower = c(0.001, 0.001), upper = c(0.999, 0.999))

muhat <- mlout@coef[1]
rhohat <- mlout@coef[2]

muhat
rhohat

expected_proportions <- updog:::dbetabinom_mu_rho(x = 0:K, size = K, mu = muhat, rho = rhohat)
expected_proportions
xtab / sum(xtab)
```

Do chi-squared test to see if the discrepancy is big
```{r}
chisq.test(x = xtab, p = expected_proportions)
```

Not that big!

# See if BB model is marginally correct for other columns

```{r}
muvec <- rep(NA, length = n)
rhovec <- rep(NA, length = n)
for (index in 1:n) {
  xtab <- table(c(samp_mat[, index], 0:K)) - 1
  mlout <- stats4::mle(negative_ll, start = list(mu = 0.3, rho = 0.3), fixed = list(xtab = xtab, size = K), method = "L-BFGS-B", lower = c(0.001, 0.001), upper = c(0.999, 0.999))

  muhat <- mlout@coef[1]
  rhohat <- mlout@coef[2]

  muvec[index] <- muhat
  rhovec[index] <- rhohat

  expected_proportions <- updog:::dbetabinom_mu_rho(x = 0:K, size = K, mu = muhat, rho = rhohat)
  print(chisq.test(x = xtab, p = expected_proportions))
}

```

Now repeat chi-squared tests given the mean estimates
```{r}
muhat <- mean(muvec)
rhohat <- mean(rhovec)
muhat
rhohat
expected_proportions <- updog:::dbetabinom_mu_rho(x = 0:K, size = K, mu = muhat, rho = rhohat)
for (index in 1:n) {
  xtab <- table(samp_mat[, index])
  print(chisq.test(x = xtab, p = expected_proportions))
}

```

No significant results! So it appears that the counts are \emph{marginally} beta binomial. Which is super interesting!

# Observed covariance between observations

There is a definite bias in the sample covariance vs the matrix I used to generate points.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
sample_cov_mat <- cov(samp_mat)
dfdat <- data_frame(sample = sample_cov_mat[lower.tri(sample_cov_mat, diag = FALSE)],
           theoretical = Sigma[lower.tri(Sigma, diag = FALSE)])
ggplot(data = dfdat, mapping = aes(x = theoretical, y = sample)) +
  geom_point() +
  theme_bw() +
  geom_abline() +
  ggtitle("Sample Cov vs 'theoretical' Cov")
```

What about correlation?

```{r, message=FALSE, warning=FALSE}
sample_cor_mat <- cor(samp_mat)
dfdat <- data_frame(sample = sample_cor_mat[lower.tri(sample_cor_mat, diag = FALSE)],
           theoretical = cov2cor(Sigma)[lower.tri(Sigma, diag = FALSE)])
ggplot(data = dfdat, mapping = aes(x = theoretical, y = sample)) +
  geom_point() +
  theme_bw() +
  geom_abline() +
  ggtitle("Sample Cor vs 'theoretical' Cor")
```


Hmm. I don't like that this constains the correlation to be so small.

```{r}
sessionInfo()
```

